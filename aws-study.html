<!DOCTYPE html>
<html lang="en">

<head>
	<title>Tomas Maiorino - Software Developers</title>

	<!-- Meta -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author" content="Tomas Maiorino">
	<link rel="shortcut icon" href="favicon.ico">
	<meta name="robots" content="noindex,nofollow">

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900" rel="stylesheet">

	<!-- FontAwesome JS-->
	<script defer src="https://use.fontawesome.com/releases/v5.8.1/js/all.js"
		integrity="sha384-g5uSoOSBd7KkhAMlnQILrecXvzst9TdC09/VM+pjDTCM+1il8RHz5fKANTFFb+gQ" crossorigin="anonymous">
	</script>

	<!-- Theme CSS -->
	<link id="theme-style" rel="stylesheet" href="assets/css/devresume.css">

</head>

<body>

	<!-- DEMO ONLY -->
	<div class="main-wrapper">
		<div class="container px-3 px-lg-5">
			<article class="resume-wrapper mx-auto theme-bg-light p-5 mb-5 my-5 shadow-border">

				<div class="resume-header">
					<div class="row align-items-center">
						<div class="resume-title col-12 col-md-6 col-lg-8 col-xl-9">
							<h2 class="resume-name mb-0 text-uppercase">AWS Study</h2>
						</div>
						<!--//resume-title-->
					</div>
					<!--//row-->
				</div>
				<!--//resume-header-->
				<hr>
				<section class="project-section py-3"></section>
				<div class="resume-body">
					<div class="row">
						<div class="resume-main col-12 col-lg-8 col-xl-9 pr-0 pr-lg-5">

							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">VPC</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>It is confined to an AWS region</p>
										<p>
											<ul class="resume-list">
												<li>The VPC is region specific, it can not extend to multiples regions.
												</li>
												<li>A reagion has many availability zone.</li>
												<li>CIDR</li>
												<li>Implied Router</li>
												<li>Route tables</li>
												<li>Internet Gateway</li>
												<li>Security Groups</li>
												<li>N.ACL</li>
												<li>VGW</li>
												<li>Custom VPC has no internet gateway</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Implied Router</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>It connects different AZ's together and connects VPC to the internet
													gateway.</li>
												<li>Each subnet will have a Route table</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Route tables</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>Each subnet must be associated with only one route table at any given
												time</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">VPC IP addressing</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>The CIDR block is the range if IP addresses that you choose for the VPC when
											create it.</p>
										<p>
											<ul class="resume-list">
												<li>The first 4 IP addresses in each subnet and the last one are
													reserved by AWS.</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Internet Gateway
								</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>Is the Gateway through which your VPC communicates with the internet, and
											with other AWS services</p>
									</div>
								</div>
							</section>
							<!--//project-section-->

							<section class="work-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Public Subnet</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>The subnets connect to each other through a implied router. It uses
												route tables to map the packages between the subnets.</li>
											<li>We can have one or more subnets per availability zone. A subnet can not
												extend to another availability zone.</li>
											<li>Its VPC has internet gateway attached to it</li>
											<li>It is associated automatically with a route table that has an entry for
												a default route pointing a VPC's internet gateway</li>
											<li>Subnets (private/public) are AZ specifics</li>
											<li>When you create a subnet, you specify the CIDR block for the subnet,
												which is a subset of the VPC CIDR block</li>
										</ul>
									</div>
								</div>
								<!--//item-->
								<!--
								<div class="item mb-3">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Senior Software
											Engineer</h4>
										<div
											class="item-meta col-12 col-md-6 col-lg-4 text-muted text-left text-md-right">
											Compasso | 2017 - 2019</div>
									</div>
									<div class="item-content">
										<p>Worked for a big brazilians ecommerce in Sao Paulo. My roles and
											responsibilities included.</p>
										<ul class="resume-list">
											<li>Responsible for the catalog integration between the Oracle Cloud
												Commerce and
												the clients catalog management tool using Spring Boot, Java 8,
												Webservices Rest,
												RabbitMQ, Docker, Kubernetes, Jira, JUnit, Mockito, Mongo, Redis, Maven
												and
												Jenkins. Helped on the architecture definition and which technologies to
												use.</li>
											<li>Develop and maintain rest apiâ€™s using Microservices, Spring Boot, Java,
												Java EE,
												JUnit, Mockito, Gradle, ldap and Weblogic. Maintain the frontend
												application
												which interacts with the rest apis using Angular 2 and Angular material.
											</li>
											<li>Isolate and rectify issues in production through the analyses of
												applications'
												source code (Java 7), systems transactions' logs (Ecommerce and OSB) and
												thread
												dumps by using the following tools (Splunk, Dynatrace, Eclipse, Sql
												developer).</li>
											<li>Generate reports through complex queries and scripts (Oracle 11) to help
												the
												business team to check the impact of some issues in production in order
												to
												proactively mitigating either any financial impact or client experience
											</li>
										</ul>
									</div>
								</div>
								-->
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Elastic IP Addresses</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>You have 5 Elastic IP's addresses per REGION</li>
												<li>NAT Gateway required Elastic IP</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Security Group</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>Statefull</li>
												<li>Only have permit rules</li>
												<li>Implicit denied at the end</li>
												<li>Associated with EC2 instances' Elastic network interface (ENI)</li>
												<li>Are VPC resources</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">N.ALC</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>It is a function performed on the implied router (the implied router
													hosts the network ACL function)</li>
												<li>Stateless, for an allowed inbound traffic must be "explicity"
													allowed too</li>
												<li>Have "permit" and "deny" rules</li>
												<li>Each rule has a number</li>
												<li>Explicity denied at the end</li>
												<li>A subnet must be associated with a N.ACL</li>
												<li>A custom (not-default) N.ACL blocks/denies all traffic inbound and
													outbound by default</li>
												<li>N.ACL rules are evaluated by rule number, from the lowest to
													highest, and executed immediately when a matching allw/deny rule is
													found</li>
												<li>When using a default configuration, by default N.ACL allows all
													inbound and outbound IPV4 traffic</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">VCP Peering</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>Allows two VPC's to communicate with each other with a highly
													available networking that enables routing traffic between the using
													private IP4/IPV6</li>
												<li>It can comunicate with another AWS account within the same region or
													between AWS regions</li>
												<li>Transitive peering relationships are not supported.</li>
												<li>Edge to Edge routing via gateway are INVALID</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">VPN</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>A secure connection over the internet or direct connect between on-premisse
											and AWS</p>
									</div>
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>Quick easy to deploy and cost effective</li>
												<li>A VGW is required on the VPC side and a customer Gateway on the
													clients data center</li>
												<li>Can not use the NAT Gateway in your VPC(?) through VPN con.</li>
												<li>Route propagationto update the route tables through VGQ and the VPN
													connection dynamically</li>
												<li>You can not access Elastic IP's on your VPC side using VPN tunnel
													estabilished</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Direct Connect (DX)</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>It is a direct connection (not internet based) and provided for
													higher speeds (bandwidth), less latency and higher performance</li>
												<li>Use one private VIF(virtual interface) to connect to your private
													VPC and one public VIF to connect to AWS public services</li>
												<li>Once connected via DX you can access all AZ's in a region</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">AWS Transit Gateway</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>A transit gateway is a network transit hub that you can use to inter
													connect your VPC and on-premises networks to a single gateway</li>
												<li>It is a REGIONAL resource</li>
												<li>It can be associated across accounts</li>
												<li>With Transit Gateway, you only have to create and manage a single
													connection from the central gateway to each Amazon VPC, on-premises
													data center, or remote office across your network</li>
												<li>If you attach a transit gateway peering connection, the transit
													gateway must be in a different region</li>
											</ul>
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Interface VPC endpoints (AWS
									private links)</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											VPC endpoints allow the connection from within a VPC to AWS service (that
											are powerd by AWS private link) privately without over the internet.
										</p>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">EC2</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>It required a KEY and Keypair name to access the instance</li>
												<li>You can add an IAM role to an EC2 instance during or after it is
													launched</li>
												<li>Dedicated Instances run on single tenante hardware</li>
												<li>Dedicated hosts run on a fully dedicated host</li>
												<li>ENI is attache when the EC2 instance is running (hot attach), when
													the instance is stopped (warn attach), when the instance is being
													launched (cold attach)</li>
												<li>You are limited to running On-demand instances per your vCPU based
													On-demand instance.</li>
												<li>Limit increased are tied to the REGION they were
													requested.</li>
												<li>If you need more instances, complete the EC2 limit increase request
													form.</li>
											</ul>
										</p>
									</div>
								</div>
								<div class="item mb-3">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Block Store</h4>
									</div>
									<div class="item-content">
										<p>Elastic block store (EBS)</p>
										<ul class="resume-list">
											<li>Persistent</li>
											<li>Networg attached virtual drives</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Instace Store
											</h4>
										</div>
										<ul class="resume-list">
											<li>Basically the virtual hard drive on the host alllocated to this EC2
												instance</li>
										</ul>
									</div>
								</div>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>Charged for data transfer in/out of EC2 instance (if sent outside
													the AWS REGION</li>
											</ul>
										</p>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Elastic Fabric
												Adapter (EFA)</h4>
										</div>
										<ul class="resume-list">
											<li>Is a network device that you can attach to you EC2 instance to
												accelerate High Performance Computing (HPC)</li>
											<li>EFA proveides lower and more consistent latency and higher throughput
												than the TCP transport traditionally used in could-based HPC sustems
											</li>
											<li>The OS-bypass capabilities of EFA's are not supported on Windows
												instnaces. OS-bypass enables HPC and machine learning applications to
												bypass the OS kernel and to communicate directly with the EFA device
											</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Enhanced
												Networking
											</h4>
										</div>
										<ul class="resume-list">
											<li>EC2 enhanced networking can function across Multi-AZ</li>
											<li>It uses SR-I/O on supported EC2 instance types to provide: higher
												inter-instance PPS rates, low latency. It does not cost extra.</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Cluster
												Placement Group
											</h4>
										</div>
									</div>
									<div class="item-content">
										<p>Clustering of EC2 instances in a single AZ</p>
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">EC2 - Partion
												PLacement Group</h4>
										</div>
										<ul class="resume-list">
											<li>AWS tries to launch your group instances into different logical entities
												called partitions</li>
											<li>Can be single or Multi-AZ in the same REGION</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">EC2 - Spread
												PLacement Group</h4>
										</div>
										<ul class="resume-list">
											<li>Lauches each instance in the group in a different hack.</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">EC2 -
												Monitoring</h4>
										</div>
										<ul class="resume-list">
											<li>EC2 check status</li>
											<li>It sends its metric data to AWS Cloud Watch every 5 min (enable by
												default)</li>
											<li>For EC2 instances Cloud Watch monitors:
												<ul>
													<li>CPU Utilization</li>
													<li>Disk Performance</li>
													<li>Disk read/write</li>
												</ul>
											</li>
											<li>To get more information, such as memoru Utilization, disk swap, page
												file, log collection. It is necessary to install a Cloud Watch agent in
												the instance</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">EC2 -
												Bastion Hosts(Linux) Remote Desktop(Windows)</h4>
										</div>
										<ul class="resume-list">
											<li>It is used to centralized the access to all EC2 instances for SSH
												requests</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">EBS</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											<ul class="resume-list">
												<li>EBS Volume data is replicated by AWS across multiple servers in the
													same AZ to prevent data loss resulting from any single AWS component
													failure</li>
												<li>Both EBS volume and EC2 must be in the same AZ</li>
												<li>EBS-backed EC2 instance has an EBS root volume</li>
												<li>Instance-Store backed EC2 instance has an instance store root
													volume. It should be used when a very high IOPS rate is required
												</li>
												<li>ELB Snapshots are stored in S3 and you can only access them through
													EC2 API</li>
												<li>You can create a Snapshot and access the volume simultaneously, if
													the instance is running</li>
												<li>EBS Snapshot are point-in-time images/copies of your EBS Volume</li>
												<li>Snapshots are REGION specific</li>
												<li>To migrate an EBS from one AZ to anothre, you have to create a
													snapshot(region specific) and create a EBS volume from the snapshot
													in the intended (other) AZ
												</li>
												<li>Snapshots are stored incrementally, what you need is a single
													snapshot, then further snapshots will only carry the changed blocks
													(incremental update)</li>
												<li>They are asynchronously created</li>
												<li>Cold HDD: Low-cost magnetic storage that focuses on throughput
													rather than IOPS. Throughput up to 250 MiB/s</li>
											</ul>
										</p>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">EBS -
												Encryption</h4>
										</div>
										<ul class="resume-list">
											<li>Encryption operation is done on the servers hosting the EC2 instances
											</li>
											<li>There is not direct way to change the Encryption state of a volume</li>
											<li>You can change the encrypted/un-encrypted status of an EBS through
												copies of snapshots</li>
											<li>When encrypting the first EBS volume, AWS creates a default CMK key</li>
											<li>You CAN NOT share snapshots encrypted using the default CMK</li>
											<li>EBS volumes are AZ specific (can be used in the AZ where they were
												created only)</li>
											<li>You CAN NOT make your encrypted snapshot public</li>
										</ul>
									</div>
								</div>
								<div class="item-content">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Redundant Array of
											Independent Disk - RAID</h4>
									</div>
									<ul class="resume-list">
										<li>Usedto increase I/O performance/throughput of your EC2</li>
										<li>RAID array is a collection of drivers (BS volumes in our case) it is
											accomplished at the OS level</li>
										<li>Stripping: Parallel writing (faster writting)</li>
										<li>Mirroring: writing the same data to multiple array disk (redundancy)</li>
										<li>RAID 10 is the best option, it combines both RAID 0 and RAID 1</li>
									</ul>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">ELB</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>ELB is a REGION specific</li>
											<li>It supports HTTP/S, TCP, SSL</li>
											<li>Frontend Listeners check for traffic from clientes to the ELB</li>
											<li>Backend Listeners are configured with protocol/port to check for traffic
												from the ELB to the EC2 instance</li>
											<li>A healthy instance show as "in-service" under the ELB</li>
											<li>Enable "cross-zone load balancing" to the CLB distribute traffic evenly
												among registered EC2 instances in different AZ's </li>
											<li>CLB needs to be enable in at least two AZ in the desired region</li>
											<li>Pay attention in the amount of availables IP's in the subnet</li>
											<li>Perfect forward secrecy is used to offer SSL/TLS cypher suite to cloud
												front and ELB</li>
											<li>An ELB Internet facing will haev a public ip for its nodes</li>
											<li>You must assign a security group to your ELB</li>
											<li>You must ensure that the subnet's N.ACL allow traffic to/from the ELB
												both ways</li>
											<li>You can defined your custom security olicies or use the ELB pre-defined
												security policies for the FE (client to ELB {TPS/SSL})</li>
											<li>Backend always uses pre-defined security policies</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Charged</h4>
										</div>
										<ul class="resume-list">
											<li>Hourly</li>
											<li>For GBS transfered through your CLB</li>
											<li>For Load balance capacity units (LCUs) per hour in case of ALB and NLB
											</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Session
												Affinity (session sticknese)</h4>
										</div>
										<ul class="resume-list">
											<li>Whereby the CLB binds a client user session/requrest to a specific
												backend EC2 instance</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Connection
												Draining</h4>
										</div>
									</div>
									<div class="item-content">
										<p>When identifying unhealthy instances, the CLB will wait for a period
											of 300 seconds (by default) for the in-flight sessions to this EC2
											instance to complete, if not finish, the ELB will force
											terminationof these sessions. Auto-scaling will honer the connection
											Draining settings for unhealthy instances</p>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Monitoring</h4>
										</div>
										<ul class="resume-list">
											<li>ELB sends metrics to CW every minute</li>
											<li>You can use CQ to send SNS notifications</li>
											<li>Access logs are disabled by default</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">ALB</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>An ALB functions at the application layer, the seventh layer of the open
											system inter connection (OSI) model. It supports HTTP/s, HTTP/2, websockets
										</p>
									</div>
									<div class="item-content">
										<ul class="resume-list">
											<li><strong>Target:</strong> being a member of a target group</li>
											<li>Health check at the target group level</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">ALB Components
											</h4>
										</div>
										<ul class="resume-list">
											<li>Listeners</li>
											<li><strong>Target Groups: </strong> confined to a Region, associated with
												only one load balancer</li>
											<li><strong>Targets: </strong> You can't mixe targets of differents types in
												one target group.</li>
											<li><strong>Rules (Condition, action, priority): </strong>Provides a link
												between the listener and the targe group. They are defined on listeners.
												You must defined a default rule for each listener</li>
											<li>Deleting a target group does not affect the targes registered with the
												target group.</li>
											<li>ALB supports enhanced CW metrics and health checks</li>
											<li>Content based routing: Host based / path based</li>
											<li>Cross zone load balancing is enabled by default</li>
											<li>You can use AWS WAF with your ALB to allow or block requests</li>
											<li>It supports SNI</li>
											<li>It supports connection draining (300 seconds by default)</li>
											<li>Enable stick sessions at the target group level</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">ALB Monitoring
											</h4>
										</div>
										<ul class="resume-list">
											<li>Sends metrics to CW every minute if there are requests flowing through
												the ALB
											</li>
											<li>Access logs</li>
											<li>Request tracing</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">NLB</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>It operates at transport layer (layer 4) only of OSI model</li>
											<li>It supports TCP and TLS listeners</li>
											<li>It supports UDP traffic</li>
											<li>It has a higher connection rates per second compared with the ELB.</li>
											<li>Health checks at the target group level</li>
											<li>Many CW metrics are also supported and reported at the target group
												level</li>
											<li>You CAN NOT enable or disable AZ's for a NLB after you create it</li>
											<li>Access logs, delete protection are disables by default on NLB</li>
											<li>Yo can use websockets with your listeners</li>
											<li><strong>Target types: </strong> IP address / Instance ID</li>
											<li>It does not supports Lambda Target type</li>
											<li>If you use the instance id as target type, NLB preserves the clients
												source IP addres, and provide them to the target</li>
											<li>If you use IP as target type, them you have to use Proxy Protocol
												(disabled by default) to send the source ip address</li>
											<li>It uses passive (the load balancer observes how targets respond to
												connections)/active health checks</li>
											<li>It supports Sever Name Indicator</li>
											<li>It DOES NOT supports connection draining</li>
											<li><a href="https://tutorialsdojo.com/application-load-balancer-vs-network-load-balancer-vs-classic-load-balancer/"
													target="_blank">Link comparing CLB, ALB and NLB</a></li>
										</ul>
									</div>
									<div class="item mb-3">
										<div class="item-content">
											<div class="item-heading row align-items-center mb-2">
												<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Monitoring
												</h4>
												<ul class="resume-list">
													<li>ELB send publisehd data points to CW for load balancars and
														targets</li>
													<li>CW can be used to verify that the NLB is performing as expected
													</li>
													<li>VPC flow logs can be used to capture detailed information about
														the traffic going to and from your NLB</li>
													<li>Create a flow log for each network interface for your load
														balancer. There is one network interface per load balancer
														subnet</li>
													<li>NLB does not support security groups</li>
													<li>Access logs are disabled by default</li>
												</ul>
											</div>
										</div>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">AUTO SCALING</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>Configure automatic scaling for the AWS resources quickly through a scaling
											plan that uses dynamic scaling and predictive scaling</p>
									</div>
									<div class="item-content">
										<ul class="resume-list">
											<li><strong>Target tracking scaling: </strong> Scale are source based on a
												target value for a specific CW metric</li>
											<li><strong>Step scaling: </strong> Based on a set of scaling adjustments
												that vary based on the size of the alarm health</li>
											<li><strong>Scheduled scaling</strong></li>
											<li><strong>AS Group: </strong> is a logical grouping of EC2 instances. You
												specify the number the instances for each AS Group</li>
											<li><strong>Scaling Policy Plan: </strong> determines when/if and how the
												ASG scales or shrinks</li>
											<li>It can span multi AZ's within the same region, but not across regions.
											</li>
											<li>There is no additional cost for lauching AS groups</li>
											<li>It works well with ELB, CW and Cloud Trail</li>
											<li>It tries to distribute EC2 instances evenly across AZ's where it is
												enabled</li>
											<li>You can attach on or mode ELB's (classic, ALB, NLB)to your existing AS
												group</li>
											<li>The ELB's must be in the same REGION as the AS group</li>
											<li>If you have an ELB defined with the AS Group, you can configured AS to
												use both the EC2 health check and the ELB health check to determine the
												instances health status. If one source reporting the instance as
												unhealthy is enough for AS to mark it for replacement</li>
											<li><strong>Cooldown period: </strong> is a configurable setting that helps
												ensure to not launch or terminate additional instances before previous
												scaling activities take effect</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Termination
												Policies
											</h4>
										</div>
										<ul class="resume-list">
											<li>OldestInstance: terminate the oldest instance in the group</li>
											<li>NewestInstance: terminate the newest instance in the group</li>
											<li>ClosestToNextInstanceHour: Terminate instances that have are closest to
												the next billing hour</li>
											<li>OldestLaunchConfiguration: Terminates instance that have the oldest
												launch configuration</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Scaling
												Policies
											</h4>
										</div>
										<ul class="resume-list">
											<li>Maintain</li>
											<li>Manual Scaling</li>
											<li>Cyclic</li>
											<li>On-demand/dynamic (event based)</li>
											<li>Predictive Scaling: Combines AWS AS with on-demand scaling (Proactive
												and reactive together)</li>
											<li>ASG can have multiple policies attached to it at any time</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Lauch
												configuration
											</h4>
										</div>
										<p>It is the template used to create new EC2 instances for the ASG. It has
											parameters like: instance family, instance type, AMI, key pair, block
											devices, and security groups</p>
										<ul class="resume-list">
											<li>You can not update a launch configuration, if you change anything,
												you have to create a new one</li>
											<li>Launch templates are similar to launch configuration and you can
												create versions of it.</li>
											<li>By using templates you can provision your capacity using on demand
												and spot instances (can't be done using launch configuration)</li>
										</ul>
									</div>
								</div>
								<div class="item-content">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Monitoring
										</h4>
									</div>
									<ul class="resume-list">
										<li>AWS EC2 service sends EC2 metrics to CW about the ASG instances</li>
										<li>Basic Monitoring(5 minutes)</li>
										<li>Detaile (every 1 minute)</li>
										<li>It can sends SNS notifications when your AS Groups launch or terminates
											instances</li>
									</ul>
								</div>
							</section>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">CLOUD FORMATION</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											It is a service that helps you model and set up your Amazon Web Services
											Resources. You can model your Cloudformation templates in JSON or YAML
										</p>
									</div>
									<div class="item-content">
										<ul class="resume-list">
											<li>You create a templace that describes all the AWS resources that you want
												(like Amazon EC2 instances or Amazon RDS DB instances),then AWS takes
												care of provisioning and configuring those resources for you.</li>
											<li>The results is called a "stack"</li>
											<li>SImplify infrastructure management: You can create, update, version
												control and delete your stacks.</li>
											<li>Quickly Replicate Your infrastructure: Just describe your resource once
												and then provision the same resources over and over in multiple REGIONS
											</li>
											<li>Easily Control and Track Changes your infrastructure: manager your
												infrastructure as code</li>
											<li>When you create a stack, AWS CloudFormation makes underlying service API
												calls to AWS to provision and configure your resources</li>
											<li>When you need to update your stack's resources, you can modify the
												stack's template, you don't need to create a new stack and delete the
												old one</li>
											<li>When you delete a stack, you specify the stack to delete, and AWS
												CloudFormation deletes the stack and ALL RESOURCES in that stack</li>
											<li>If AWS CloudFormation can not delete a resource, the stack WILL NOT be
												deleted</li>
											<li>CloudFormation design is a graphic toll for creating, viewing and
												modifying AWS CloudFormation templates.</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">BEANSTALK</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											It is an easy service for deploying and scaling web applications and
											services deployed with supported programming langhates,on familiar servers
											such as Apache, Nginx, Passenger, Docker, Tomcat and IIS.
										</p>
									</div>
									<div class="item-content">
										<ul class="resume-list">
											<li>Simply upload your application, and Beanstalk automatically handles the
												details of capacity provisioning, load balancing, scaling and
												application health monitoring.</li>
											<li>It provisions the resources needed to run your application, including
												one or more EC2 instances.</li>
											<li>Elastic Beanstalk applications run on EC2 instances that have no
												persistent local storage.</li>
											<li>You should design your application to store data in a persistent data
												source.</li>
											<li>Your Elastic Beanstalk environment can become unusable if you don't use
												Elastic Beanstalk funcionality to modify or terminate the environment's
												underlying AWS resources</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Beanstalk
												Components: Application</h4>
										</div>
										<ul class="resume-list">
											<li>An application server as a container for the environment that run you
												web app, and versions of you web app's source code, saved configuration,
												logs an other artifacts that you create while using Elastic Beanstalk
											</li>
											<li>An Beanstalk application is a logical collection of Elastic Beanstalk
												components, including environments, versions and environment
												configurations.
												An applicaion is concepltually similar do a folder.
											</li>
											<li>An application version points to an S3 object that contains the deployed
												code such as Java War</li>
											<li>In a running environment, you can deploy any application version you
												already uploaded to the application,or you can upload and imediately
												deploy a new application version</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Beanstalk
												Components: Environment</h4>
										</div>
										<ul class="resume-list">
											<li>is a version that is deployed onto AWS Resources</li>
											<li>Each environment runs only a single application version at a time.</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Ops Works</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>
											Ops Works Stacks provides a simple and flexible way to create and manage
											stacks and applications.
										</p>
									</div>
									<div class="item-content">
										<ul class="resume-list">
											<li>The stack is the core AWS OpsWorks component.</li>
											<li>OpsWorks allows ssh and RDP access to stack instances</li>
											<li>Resources can be managed only in the region in which they are created
											</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">CHEF</h4>
										</div>
										<ul class="resume-list">
											<li>Chef provides automated configuration management that enables consistent
												configurations at scale</li>
											<li>Chef helps in ensuring that configuration, policy is
												flexible,versionable, testable and human readable.</li>
											<li>cookbooks: it is a package file containing configuration information,
												including instructions called recipes</li>
											<li>Recipes: A recipe is a set of one or more instructions written in Ruby
												language syntax, that specifies the resources to use</li>
											<li>Resources: In Chef terms, A resource, as used in Chef is a statement of
												configuration policy (this is different from what a resource is to
												OpsWorks</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Snowmobile</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>
												An exabyte-scale data transfer service used to move extremely large
												amounts of data to AWS, You can transfer up to 100PB per snowmobile
											</li>
											<li>Snowmobile will be returned to your designated AWS region where you data
												will be uploaded into the AWS storage services you have selected, such
												as S3 or Glacier</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Snowball edge</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>
												A type of Snowball device with on-board storage and compute power for
												select AWS capabilities. It can undertake local processing and
												edge-computing workloads in addition to transferring data between your
												local environment and AWS cloud
											</li>
											<li>Storage Optimized: up to 80TBof useable storage (it has most storage
												capacity)</li>
											<li>Compute Optimized: Is has most compunte funcionality. This options also
												comes with 42TB of additional storage space</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">RDS</h3>
								<div class="item mb-3">
									<p>It is a fully managed relational DB engine service</p>
									<ul class="resume-list">
										<li>Best suit for OLTP (Online Transaction Processing - Read/Writes)</li>
										<li>It supports:
											<ul>
												<li>MS SQL Server</li>
												<li>Oracle</li>
												<li>PostgreSQL</li>
												<li>Maria DB</li>
												<li>Mysql</li>
												<li>AWS Aurora</li>
											</ul>
										</li>
										<li>It uses EBS volumes</li>
										<li>General Purpose(GP2) RDS storage: Used for DB workloads with moderate I/O
											requirements</li>
										<li>Provisioned IOPS(io1) RDS storage: Used for high performance OLTP workloads
										</li>
										<li>Magnetic RDS Storage</li>
										<li>RDS supports encryption at rest and supports SSL encryption for
											communication between the DB clients and RDS DB instances</li>
										<li>Reserved instances are REGION specific</li>
										<li>You can have UP to 40 RDS DB instances</li>
										<li>Point-in-time restore and snapshot features for RDS of Mysql are only
											supported by InnoDB engine</li>
										<li>RDS storage Auto Scaling automatically scales storage capacity</li>
										<li><strong>Instances classes types: </strong> Standard, Memoru Optimized and
											Burstable Performance</li>
										<li>You can change the CPU and memory available to a DB instance by changing its
											DB instance class</li>
										<li>Deletion protection is disabled by default</li>
									</ul>
								</div>
								<div class="item mb-3">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Enhanced Monitoring
											for RDS instances
										</h4>
									</div>
									<ul class="resume-list">
										<li>RDS child processes</li>
										<li>RDS processes</li>
										<li>OS processes</li>
									</ul>
								</div>
								<div class="item mb-3">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Multi-AZ option
										</h4>
									</div>
									<ul class="resume-list">
										<li>It provides high availability, data durability, and fault tolerance for DB
											instances.</li>
										<li>Oracle, Mysql, Maria DB, PostgreSQL uses failover technology</li>
										<li>You can select the Multi-AZ option during RDS DB instance launch or modify
											an existing standalone RDS instance</li>
										<li>It creates an standby instance in a different AZ in the same REGION and
											configure "synchronous" replication between the primary and standby</li>
										<li>You CAN NOT read/write from/to a standby RDS instance</li>
										<li>You'll be alerted by a DB instance event when a failover occurs (SNS)</li>
										<li>The canonical name record (CNAME)is swicth from the primary to the stand by
											if the primary fails</li>
										<li>Actions done in the stand by instance
											<ul>
												<li>OS patching</li>
												<li>DB scaling</li>
												<li>System upgrade</li>
												<li>Snapshot / Auto backup</li>
												<li>Maintenance</li>
												<li>DB engine versio upgrade (both primary and replica must have the
													same version)</li>
											</ul>
										</li>
									</ul>
								</div>
								<div class="item mb-3">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Backup / Snapshot
										</h4>
									</div>
									<ul class="resume-list">
										<li>You can share only manual backups</li>
										<li>Retention period: 7 days</li>
										<li>Automatic backups are incremental (snapshot)</li>
										<li>You can not restore into an existing DB instance, it has to be a new DB
											instance with a new instance/db endpoint</li>
										<li>You can change the storage type (magnects, provisioned IOP, geleram purpose)
											during a restore process</li>
										<li>Automatic backup MUST be enable and remain enabled for read replicas to work
										</li>
										<li>Read replicas can be created in the same REGION as the master and also in a
											different region</li>
										<li>Read replicas are done using asynchronous replication</li>
									</ul>
								</div>
								<div class="item mb-3">
									<div class="item-heading row align-items-center mb-2">
										<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">IAM Authentication
											for Mysql and PostgreSQL</h4>
									</div>
									<p>It is a mechanism that allows authentication to access the RDS instance without
										use a password when you connect to a DB instance, instead you use authentication
										token (expires in 15 minutes), the authentication is managed externaly using IAM
									</p>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">AURORA DB</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>It is compatible with Mysql and PostgreSQL</li>
											<li>Multi-AZ (one region)</li>
											<li>An Aurora dbclister consist of one or more DB instances and a cluster
												volume that manages the data for those DB instances</li>
											<li><strong>Primary DB instance: </strong> supports reads and writes</li>
											<li><strong>Aurora Replicas: </strong> supports only read operations</li>
											<li><strong>Cluster endpoint: </strong> connects to the current primery DB
												instance (the only one that can perform write operations)</li>
											<li><strong>Reader endpoint: </strong> connects to on of the available
												Aurora Replicas for that DB cluster (used for only read operations)</li>
											<li><strong>Instance endpoint: </strong> </li>
											<li><strong>Custom endpoint: </strong> </li>
											<li>You can use IAM database authentication to authenticate to your Aurora
												Mysql</li>
											<li>It uses a VPC security group to control which devices and EC2 instances
												can open connections to the Aurora endpoint and port</li>
											<li><strong>Aurora Global Database: </strong>it consist of one primary AWS
												region where data is mastered, and one read only secondary AWS region
											</li>
											<li>You use Aurora mysql native functions to invoke lambda functions</li>
											<li>?Loading data from S3 and save queries results in S3</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Backup tracking
											</h4>
										</div>
										<p>It provides an easily way to undo mistakes, backtracking a DB cluster does
											not require a new DB cluster and rewinds the cluster in minutes
										</p>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Monitoring</h4>
										</div>
										<ul class="resume-list">
											<li>Cloud trails</li>
											<li>Enhanced monitoring (for the OS and DB cluster)</li>
											<li>Amazon RDS performance insights</li>
											<li>Aurora Event Notification using SNS</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Aurora Servless</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>It is an on-demand, auto-scaling configuration for Aurora</li>
											<li>A non-serveless DB cluster for Aurora is called a provisioned DB cluster
											</li>
											<li>It manages the warnpool of resources in an AWS region to minimize
												scaling time</li>
											<li>The cluster volume for an Aurora Serveless cluster is always encrypted
											</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">AWS SNS</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>Is an event-driver computing hub that has native integration with a wide
											variety of AWS event sources (including EC2, S3 and RDS) and AWS event
											destinations (including SQS and lambda)<br>
											<strong>Event-driver computing </strong>is a model in which subscriber
											services
											automatically perform work in response to events triggerred by publisher
											services.</p>
										<ul class="resume-list">
											<li>
												It sores all topic and message information within Amazon's proven
												network infrastructure and data center at least three copies of data are
												stored accross multiple AZ's</li>
											<li>Published iamges maximum limitsare 256kb</li>
											<li><strong>SNS mobile notifications </strong>allows you to fanout mobile
												push notifications to iOS, Android, FireOS, Windows and Baidu based
												devices.</li>
											<li>You pay based on the number of notifications you publish, the number of
												notifications you deliver</li>
											<li>You can have a Lambda function, a SQS queue and an Http/s endpoint as
												subscribers.</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Cloud Trail
												logs</h4>
										</div>
										<ul class="resume-list">
											<li>SNS api called</li>
											<li>Source id address</li>
											<li>time of the api call</li>
											<li>Request parameters</li>
											<li>Response elements returned by SNS</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">Cloud Trail</h3>
								<div class="item mb-3">
									<div class="item-content">
										<p>CloudTrail focuses on auditing API activity.<br>
											Actions taken by a use, role, or an AWS service in the AWS management
											console, AWS command line interface and AWS SDKs and APIS are recorder as
											events</p>
										<ul class="resume-list">
											<li>When activity occours in yout AWS account that activity is recorded in a
												CloudTrail event.</li>
											<li>Create a CloudTrail trail to archive, analyze and respond to changes in
												your AWS resources</li>
											<li>A cloudtrail trail is a configuration that enables delivery of events to
												an S3 bucket that you specify. It can be in another region</li>
											<li>You can create an organization trail that will log all events for all
												AWS accounts in an organization created by AWS Organizations</li>
											<li>CloudTrail loggin, which is basically sending the cloudtrail events to a
												bucket, is not enabled by default</li>
											<li>It enables governance, complienced, operational auditing and risk
												audition for your AWS account</li>
										</ul>
									</div>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Monitoring</h4>
										</div>
										<p>Uses CloudWatch logs file integrity validation to determine whether a log
											file was
											modified, deleted or unchanged after cloudtrail has delivered it to your S3
											bucket</p>
										<ul class="resume-list">
											<li>SNS notification</li>
											<li>CW -> it can send events to CW logs and you can trigger alarms according
												to the metrics filters you define</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">AWS Config TODO</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>
												Is a service that enables you to access, audit, and evaluate the
												configurations of your AWS reources.</li>
											<li>It monitors and records your AWS resources configuration</li>
											<li>You can use a config rule to check IAM_PASSWORD_POLICY on an account
											</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<h3 class="text-uppercase resume-section-heading mb-4">AWS Shield</h3>
								<div class="item mb-3">
									<div class="item-content">
										<ul class="resume-list">
											<li>AWS Shield is a managed Distributed Denial of Service (DDoS) protection
												service that safeguards applications running on AWS</li>
											<li>It proveis always-on detection and automatic inline mitigations that
												minimiza application downtime and latency</li>
										</ul>
									</div>
								</div>
							</section>
							<section class="project-section py-3">
								<section class="project-section py-3">
									<h3 class="text-uppercase resume-section-heading mb-4">Cloud Watch TODO</h3>
									<div class="item mb-3">
										<div class="item-content">
											<p>
												<ul class="resume-list">
													<li></li>
												</ul>
											</p>
										</div>
										<div class="item-content">
											<div class="item-heading row align-items-center mb-2">
												<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">AWS
													CloudWacth Agents</h4>
											</div>
											<ul class="resume-list">
												<li>To collect logs from a EC2 instances and on-premises services you
													have
													to use either an unified CloudWacth Agent, or the old one CloudWacth
													Logs agent</li>
												<li>Unified agent also enables the collection of additional system
													metrics,
													for in-guest visibility</li>
											</ul>
										</div>
										<div class="item-content">
											<div class="item-heading row align-items-center mb-2">
												<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">AWS
													CloudWacth Monitoring Scripts</h4>
											</div>
											<ul class="resume-list">
												<li>As CloudWacth does not monitor EC2 memory usage as well as disk
													space utilization. You would have to collect the metrics using a
													script or by using a CloudWacth agent, then send the data to
													CloudWacth</li>
											</ul>
										</div>
									</div>
								</section>
								<section class="project-section py-3">
									<h3 class="text-uppercase resume-section-heading mb-4">S3 TODO</h3>
									<div class="item-content">
										<div class="item-heading row align-items-center mb-2">
											<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Encryption
											</h4>
										</div>
										<ul class="resume-list">
											<li>SSE-KMS provides an audit trail that shows when your CMK was used and by
												whom. You can also create and manage customer-managed CMKs or use WAS
												managed CMKs that are unique to you, your service, and your region
											</li>
										</ul>
									</div>
									<div class="item mb-3">
										<div class="item-content">
											<div class="item-heading row align-items-center mb-2">
												<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Monitoring
												</h4>
											</div>
											<ul class="resume-list">
												<li>Server access logging give access to referrer and turn-around time
													and
													provides you visibility into object-level operations on your data in
													S3
												</li>
											</ul>
										</div>
										<div class="item-content">
											<div class="item-heading row align-items-center mb-2">
												<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">AWS
													S3 Transfer Acceleration</h4>
											</div>
											<ul class="resume-list">
												<li>Enables fast, easy , and secure transfer of files over log
													distances
													between your client and your S3 bucket</li>
												<li>Tranfer Acceleration leverages Amazon CloudFront's globally
													distributed edge locations</li>
												<li>It improves performace for a wide range of applications over TCP
													or
													UDP by proxying packages at the edge to applications running in
													one
													or more ARS Regions</li>
												<li>It routes the traffic to the closest edge location via Anycast
												</li>
											</ul>
										</div>
								</section>
								<section class="project-section py-3">
									<h3 class="text-uppercase resume-section-heading mb-4">AWS Global Accelerator</h3>
									<div class="item mb-3">
										<div class="item-content">
											<ul class="resume-list">
												<li>
													Is a service that improves the availability and performance of your
													applications with local or global users.
												</li>
												<li>It provides static IP address that act as a fixed entry point to
													your
													application endpoints in a single or multiple AWS Regions, such as
													ALB,
													NLB and EC2 instances</li>
											</ul>
										</div>
									</div>
								</section>
								<section class="project-section py-3">
									<h3 class="text-uppercase resume-section-heading mb-4">AWS Step Functions</h3>
									<div class="item mb-3">
										<div class="item-content">
											<ul class="resume-list">
												<li>A fully managed service that makes it easy to coordinate the
													components
													of distributed applications and microservices using visual
													workflows.</li>
												<li>It provides servless orchestration for modern application.
													Orchestration
													centrally manages a workflow by breaking it into multiple steps. As
													your
													applications execute, Step Functions maintains application state.
												</li>
												<li>You can user Step Functions to coordinate multiple AWS services into
													servless workflows</li>
												<li>You define <strong>state machines </strong> that describe you
													workflow as a series of steps, their relathionship, and their inputs
													and outputs. State machines contain a number of states, each of
													which represents an individual step in a workflow diagram</li>
											</ul>
											</p>
										</div>
									</div>
								</section>
								<section class="project-section py-3">
									<h3 class="text-uppercase resume-section-heading mb-4">Amazon Simple Workflow (SWF)
									</h3>
									<div class="item mb-3">
										<div class="item mb-3">
											<div class="item-content">
												<p>
													A fully-managed state tracker and task coordinator in the Cloud. You
													create desired workflow with their associated tasks, and any
													conditional
													logic you wish to apply and store them with SWF.
												</p>
											</div>
											<div class="item-content">
												<ul class="resume-list">
													<li>Is a web service that makes it easy to coordinate work across
														distributed applications</li>
													<li>SWF tasks represent invocations of logical steps in
														applications. Tasks are processed by workers which are program
														that interact with Amazon SWF to get tasks, process them and
														return their results.</li>
													<li>SWF API actions are task oriented. SQS API actions are message
														oriented</li>
													<li>Storage Optimized: up to 80TBof useable storage (it has most
														storage
														capacity)</li>
													<li>Compute Optimized: Is has most compunte funcionality. This
														options
														also comes with 42TB of additional storage space</li>
													<li>SWF lets you write your application components and coordination
														login in any programming language anr run them in the cloud or
														on-premises</li>
													<li>It ensures a task is never duplicated and is assigned only once.
													</li>
												</ul>
											</div>
										</div>
								</section>
								<section class="project-section py-3">
									<h3 class="text-uppercase resume-section-heading mb-4">Redshift</h3>
									<div class="item mb-3">
										<div class="item mb-3">
											<div class="item-content">
												<p>
													Datawarehouse is a relation database that is designed for query and
													analysis rather than for transacional processing.
												</p>
											</div>
											<div class="item-content">
												<ul class="resume-list">
													<li>To perform analytics you need a datawarehouse not a regurar DB
													</li>
													<li><strong>OLAP (Online Analytics Processing)</strong> is
														characterized
														by relatively low volume fo transctions. Queries are ofter very
														complex and involves aggregations.</li>
													<li><strong>OLTP (RDS, Mysql)</strong> is a database where there is
														detailed and current data, and a schema is used to store
														transactional data.</li>
												</ul>
											</div>
											<div class="item-content">
												<ul class="resume-list">
													<li>Redshift is an AWS fully-managed petabyte scale datawarehouse
														service in the cloud.</li>
													<li>It gives you fast querying capabilities over structured data
													</li>
													<li>Queries are distributed and parallelized across multiples
														physical
														resources</li>
													<li>It can store huge amount of data, but can't ingest huge amount
														of
														data in real time</li>
													<li>It is 10 times faster than a tradicional SQL RDMS</li>
													<li>It supports encryption of data at rest (AEC-256 bits)</li>
													<li>It supports SSL encryption, in transit , between client
														applications
														and redshift cluster</li>
													<li>You can not have direct access to your redshift instance custer
														nodes, however, you can through the applications themselves</li>
													<li>It can start small and grow as required.</li>
													<li>For a muli-node deployment(cluster), you need a leader node and
														compute nodes</li>
													<li>Redshift can asynchronously replicate your snapshot to S3 in
														another
														region for DR</li>
												</ul>
											</div>
											<div class="item-content">
												<div class="item-heading row align-items-center mb-2">
													<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">
														Redshift
														Performance</h4>
												</div>
												<ul class="resume-list">
													<li>It uses columnar data storage</li>
													<li>Advanced compression</li>
													<li>Massive parallel processing(MPP)</li>
												</ul>
											</div>
											<div class="item-content">
												<div class="item-heading row align-items-center mb-2">
													<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">
														Redshift
														Backup</h4>
												</div>
												<ul class="resume-list">
													<li>It stores backup (incremental snapshot) automatically for a
														user-defined retention period in S3</li>
													<li>It keeps the backup by default for one day, it can be configured
														0
														-> 35 days</li>
													<li>Manual backups are not deleted automatically if you delete a
														cluster
													</li>
													<li>Redshift supports only ONE AZ</li>
													<li>You can restore from a new redshift cluster in the same or
														different
														AZ</li>
												</ul>
											</div>
											<div class="item-content">
												<div class="item-heading row align-items-center mb-2">
													<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">
														Redshift
														Monitoring</h4>
												</div>
												<ul class="resume-list">
													<li>Metrics for compute Utilization, storage Utilization, and
														read/write
														traffic to your redshift are available for free in the AWS
														console
														or CloudWacth</li>
													<li>You can add additional, user-defined metrics via CloudWacth
														custom
														metric</li>
												</ul>
											</div>
											<div class="item-content">
												<div class="item-heading row align-items-center mb-2">
													<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">
														Redshift
														Spectrum</h4>
												</div>
												<ul class="resume-list">
													<li>It allows you to directly run SQL queries against exabytes of
														data
														IN S3</li>
													<li>You are chaged for the number of bytes scanned by redshift
														spectrum
													</li>
													<li>User redshift enhanced VPC routing to force all of the copy and
														unload traffic to go through the VPC privately through
														endpoints.
														You can use VPC flow logs to monitor copy/unload traffic
													</li>
													<li>You pay for compute node hours, backup storage and data transfer
													</li>
												</ul>
											</div>
										</div>
								</section>
								<section class="project-section py-3">
									<h3 class="text-uppercase resume-section-heading mb-4">DataSync</h3>
									<div class="item mb-3">
										<div class="item mb-3">
											<div class="item-content">
												<p>An online data transfer service that simplifies, automates, and
													accelerates copying large amounts of data to and from AWS storage
													service over the internet or AWS Direct Connect</p>
											</div>
											<div class="item-content">
												<ul class="resume-list">
													<li>You can copy data between NFS or Server Message Block (SMB) file
														servers</li>
													<li>S3 buckets</li>
													<li>EFS</li>
													<li>FSx for Windows</li>
													<li>You can store data directly into S3 standard, S3
														Intelligent-Tiering, S3 Standard-IA, S3 Glacier, S3 Glacier Deep
														Archive</li>
												</ul>
											</div>
											<div class="item-content">
												<div class="item-heading row align-items-center mb-2">
													<h4 class="item-title col-12 col-md-6 col-lg-8 mb-2 mb-md-0">Use
														Cases
													</h4>
												</div>
												<ul class="resume-list">
													<li>Data migration to S3, EFS or FSx for Windows File Server</li>
													<li>Data processing for hybrid workloads</li>
													<li>If you have large amounts of cold data storage in expensive
														on-premises storge systems, you can move this data directly to
														durable and secure long-term storage sush as S3</li>
													<li>DataSync is ideal for online data transfer. Snowball/Snowball
														edge
														is suitable for offline data transfer</li>
													<li>Use AWS datasync to migrate existing data to S3, and then use
														the
														File Gateway to retain access to the migrate data and for
														ongoing
														updates from your on-premises file-based applications</li>
												</ul>
											</div>
										</div>
								</section>
								<!--//work-section-->
						</div>
					</div>
					<!--//row-->
				</div>
				<!--//resume-body-->
				<hr>
				<div class="resume-footer text-center">
					<ul class="resume-social-list list-inline mx-auto mb-0 d-inline-block text-muted">
						<li class="list-inline-item mb-lg-0 mr-3"><a class="resume-link"
								href="https://github.com/tomasmaiorino" target="_blank"><i
									class="fab fa-github-square fa-2x mr-2" data-fa-transform="down-4"></i><span
									class="d-none d-lg-inline-block text-muted">https://github.com/tomasmaiorino</span></a>
						</li>
						<li class="list-inline-item mb-lg-0 mr-3"><a class="resume-link"
								href="https://www.linkedin.com/in/tomasmaiorino" target="_blank"><i
									class="fab fa-linkedin fa-2x mr-2" data-fa-transform="down-4"></i><span
									class="d-none d-lg-inline-block text-muted">https://www.linkedin.com/in/tomasmaiorino/</span></a>
						</li>
						<!-- <li class="list-inline-item mb-lg-0 mr-lg-3"><a class="resume-link" href="#"><i
                        class="fab fa-twitter-square fa-2x mr-2" data-fa-transform="down-4"></i><span
                        class="d-none d-lg-inline-block text-muted">@twittername</span></a></li>
                        -->
					</ul>
				</div>
			</article>
		</div>
		<!--//container-->

		<footer class="footer text-center py-4 hidden-print">
			<!--/* This template is released under the Creative Commons Attribution 3.0 License. Please keep the attribution link below when using for your own project. Thank you for your support. :) If you'd like to use the template without the attribution, you can buy the commercial license via our website: themes.3rdwavemedia.com */-->
			<small class="copyright text-muted">Designed with <i class="fas fa-heart"></i> by <a class="theme-link"
					href="http://themes.3rdwavemedia.com" target="_blank">Xiaoying Riley</a> for developers</small>
		</footer>

	</div>
	<!--//main-wrapper-->
</body>

</html>